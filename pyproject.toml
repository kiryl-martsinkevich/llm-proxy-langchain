[project]
name = "llm-proxy"
version = "0.1.0"
description = "Anthropic-compatible API proxy for OpenAI-compatible backends"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.32.0",
    "langchain-openai>=0.3.0",
    "pydantic>=2.10.0",
    "pydantic-settings>=2.6.0",
    "pyyaml>=6.0.2",
    "sse-starlette>=2.2.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.3.0",
    "pytest-asyncio>=0.25.0",
    "httpx>=0.28.0",
]

[project.scripts]
llm-proxy = "llm_proxy.main:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src/llm_proxy"]

[tool.pytest.ini_options]
asyncio_mode = "auto"
testpaths = ["tests"]
